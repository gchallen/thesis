\chapter{Lessons Learned and Future Work}
\label{chapter-lessons}

This chapter summarizes some key observations and lessons that have emerged
from the work described in this dissertation. We describe a set of important
takeaways from our experiences deploying real systems, while also identifying
some strengths and weaknesses of two architectures described in the preceding
chapters. We also briefly outline areas for future work.

\section{Lessons Learned}

Broadly speaking, we can divide the takeaways mentioned here into two
categories. The first set relate to why and how to build applications and
perform field deployments. These have emerged from the process of building
and deploying three solutions in the context of the volcano monitoring
application. The second set comment on the strengths and weaknesses of the
two architectural solutions to sensor network resource management we have
presented: Lance and IDEA.

\subsection{Deployment Lessons}

Sensor network deployments, particularly in remote areas, involve significant
cost in terms of time and equipment. Failures of hardware and software can
have a negative impact on the uptake of this technology by domain science
experts. Our experiences at Ecuadoran volcanos have yielded a number of
valuable lessons for future sensor network deployments. 

\begin{itemize}

\item \textbf{Ground truth and self-validation mechanisms are critical.}
During our 2005 deployment, we did not initially consider colocating several
of our wireless sensors with existing data loggers in order to establish
ground truth. This would have clearly aided our analysis, though we were
fortunate to locate one of our sensors near (but not immediately adjacent to)
the RVEN station. In addition, self-validation mechanisms are needed to
provide detailed information on the health and accuracy of the data recorded
by the network. The periodic ``heartbeat'' messages that we built into our
system proved essential to remotely tracking system operation.

More generally, it is critical to design the evaluation process well before
the system being studied is designed and deployed. Deployments are expensive
and deployment time is valuable, and if the system is not properly
instrumented it can be difficult to assess its performance after the
deployment has ended.

\item \textbf{Coping with infrastructure and protocol failures.} As discussed
previously, in 2005 we were surprised to find that the sensor nodes
themselves were the most reliable components of the system. Even without
classifying the 3-day network outage as an infrastructure failure, this
downtime was far exceeded by outages caused by power failures at the base
station. We did not devote enough attention to assuring the reliability of
the base station and radio modem infrastructure, assuming it would be a
trivial matter of plugging into wall power. This single point of failure was
more fragile than expected.

Additionally, several pieces deployed software, including Deluge and FTSP,
exhibited failures in the field than we not had expected given our laboratory
experiments. These failures both speak for and show the limitations of
careful, pre-deployment testing. While we were fortunate to be able to
correct protocol errors in the field and during post-processing, the risk
of uncorrectable problems argues for more rigorous testing and analysis. At
the same time, the unpredictability of field deployments places demands on
the flexibility and adaptability of the researchers involved.

\item \textbf{Building confidence inside cross-domain scientific
collaborations.} It is important when working with domain scientists to
understand their expectations and plan carefully to meet them. There can be
tensions between the desire of computer science researchers to develop more
interesting, sophisticated and complex systems, and the needs of domain
science, which relies upon thoroughly validated instrumentation. Pushing more
complexity into the sensor network can improve lifetime and performance, but
the resulting system must be carefully validated before deployment to ensure
that the resulting data is scientifically accurate.

Good communication between computer and domain scientists is also critical.
During the 2005 deployment, the seismologists were eager to see the collected
signals, which were initially in an unprocessed format with timing errors as
described earlier. From the CS perspective, the early data provided evidence
of successful data collection, but from the geophysics perspective it
highlighted failures in the time synchronization protocol. It took a great
deal of effort after the deployment to build confidence in the validity of
our data.

Finally, the development of Lance required a great deal of exchange between
the domain and computer scientists involved. Seismologists are used to systems
able to provide complete, high-fidelity signals from all stations spanning
all time intervals. The capabilities of the instruments that they typically
deploy have meant that they have not had to think about how to classify data
once not all signals have been collected. Although they were initially quite
hesitant, we were able to convince them that the easy of deployment and
promise of increased spatial resolution provided by our low-power devices
made it worth abandoning complete temporal coverage. Once convinced, they
were very helpful in suggesting ways to prioritize collected signals and
suggested the node-level summarization functions used during the 2007
deployment.

\end{itemize}

\subsection{Architectural Lessons}

\begin{itemize}

\item \textbf{Balance centralization and decentralization.} Many sensor
network architectures have discarded centralized approaches as inimical to
the goal of scaling to hundreds of nodes. Lance takes a different approach,
and attempts to balance the advantages of centralization --- such as
increased visibility and the ability to implement network-wide optimizations
--- against the overhead of transmitting data to a single location. Lance
derives the utility of sampled data using a two step process: node-level
summarization, which reduces the amount of data that must be transmitted to
the sink, and the final application utility determination and policy module
operation which occurs at the base station.

\item \textbf{Energy is the most important resource.} Both Lance and IDEA
are driven by the need to manage energy consumption. Energy --- above
bandwidth, storage, or computation --- is the defining resource in wireless
sensor networks. While Lance was designed to manage both bandwidth and
energy, in most cases the energy consumption of each wireless link supersedes
the bandwidth limitations in terms of controlling link usage.

IDEA maintains this focus while attempting to provide a general-purpose
framework for allowing energy usage to drive decision making. Many existing
sensor network protocols embed energy awareness into protocol-specific code,
resulting in approaches that may conflict with each other or fail to react
well when differences in load and charging rates arise. The development of
IDEA observed the need to manage energy as a network resource, and we believe
that it will aid in the development of new, energy-aware components.

\item \textbf{Treat the entire network as a single instrument.} Particularly
when supporting scientific study, it is important to consider a sensor
network as a set of devices cooperating to support a single application. Both
Lance and IDEA willingly trade off the performance or availability of certain
nodes in exchange for more data or better performance from others. IDEA
attempts to move the network toward globally-optimal states using node-local
decisions. It remains as future work to study in detail how effective this
approach is when compared with ones possessing a consistent global view of
the entire network, but treating the entire network as a single instrument
drives architectures that connect local node behavior with the performance of
the entire system as seen by the application.

\end{itemize}

\section{Future Work}

Despite advances in this area, sensor networks have just begun to make
inroads in augmenting and replacing existing scientific instrumentation. The
macroscope is still a new instrument, and requires much more research and
development before it can truly deliver the kind of views envisioned by de
Rosnay.

Opportunities remain for collaborations between sensor network researchers
and domain scientists in many areas. As described in
Chapter~\ref{chapter-related}, parallel efforts have already succeeded in
leveraging this technology to study animal habitats and behavior and a
variety of natural environments. Moving forward we expect to see these kinds
of scientific sensor networks defining an unique research agenda, with
emphasis on scaling out to thousands or millions of nodes, delivering large
amounts of high-fidelity data, and achieving perpetual operation predicated
on improved energy-harvesting capabilities.

These goals will continue to place pressure on key system capabilities
developed by the research described in this dissertation. Resources will
still be precious, and must be devoted to the most important information; and
energy availability will vary across the network in unpredictable ways,
potentially threatening high-fidelity operation.

The Lance architecture described in Chapter~\ref{chapter-lance} was broadened
and decentralized to produce IDEA, but several core challenges still remain.
Lance's linear policy modules are easy to use and compose, but it remains
unclear whether more complex interactions between policy modules are needed.
During the process of adapting Lance to support medical monitoring the policy
module architecture was revisited and extended, but incorporating additional
applications may require additional changes and more generality.
Additionally, Lance's reliance on a central controller limits the scalability
of the architecture. While IDEA allows certain kinds of resource-management
decisions to be made in a distributed fashion, it does not completely
eliminate the need for complete network visibility when trying to optimize
certain tasks. Instead of aiming at a completely flat network, Lance may
adapt well to tiered systems that achieve scalability without moving nodes
too far away from devices with significant computational capabilities.

As far as IDEA, for future work we are interested in addressing the problem
of cross-component interaction which would allow us to optimize the operation
of several IDEA components running in the network simultaneously. This is
complicated by the fact that there is likely to be dependencies between
components that cause decisions made by one to affect others. As an example,
the LPL intervals used by a node would effect the power cost to use the link
seen by the routing protocol. Considering cross-component interaction also
rapidly expands the search space when nodes try to identify the right local
state to select. Currently we assume that the search space is small enough
that we can search it exhaustively. Cross-component support may require that
we develop more intelligent search strategies in order to allow this process
to be performed on computationally-constrained devices.

In addition we are investigating ways to model the impact of node failure on
other nodes. Many sensor network protocols will try to work around nodes
leaving the network or going offline, but this repair process is costly and
causes load within the network to shift in ways that are difficult to
anticipate \textit{a priori}. One option here is to use network-level
simulators running in parallel with the deployed system itself. Information
about the deployment environment can be harvested continuously to increase
the reality of the simulated outcomes. When trying to adjust network
behavior, the impact of various decisions could be evaluated quickly in
simulation incorporating the effect of node failures.

Finally, further study is required to determine how close our locally-driven
state search can get to the global network-wide optimal. This is particularly
important when determining the proper distance to distribute energy state
information. Distributing state across the entire network would, in
principle, allow a globally-optimal state to be determined. However, this
would be costly, with the energy overhead likely outweighing improvements in
energy consumption achievable through protocol tuning. At the other extreme,
only sharing state locally can prevent nodes from understanding the complete
impact of their energy-management decisions, but has considerably lower
overhead. Understanding how to choose the right midpoint between these
extremes will further improve the network's performance.
