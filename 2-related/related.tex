\section{Related Work}
\label{chapter-relatedwork}

\XXXnote{GWA: Pulled from Sensys'08 introduction. Perhaps some useful
references.}

Many sensor network applications involve the acquisition
of high-resolution signals using low-power wireless sensor nodes. Examples
include monitoring acoustic, seismic, and vibration waveforms in
bridges~\cite{ggb-ipsn07}, industrial equipment~\cite{intel-northseasensys}, 
volcanoes~\cite{volcano-osdi06}, and animal
habitats~\cite{girod-ipsn07,enviromic}.  These systems all attempt to acquire
high data-rate (100~Hz or higher), high-fidelity data across the network,
subject to severe constraints on radio bandwidth and energy usage.

\XXXnote{GWA: Pulled from OSDI'06 related work.}

While the number of sensor network deployments described in the literature
has been increasing, little prior work has focused on evaluating sensor
networks from a scientific perspective.  In addition, the high data rates and
stringent timing accuracy requirements of volcano monitoring represent a
departure from many of the previously-studied applications for sensor
networks.

{\bf Low-data-rate monitoring:} The first generation of sensor network
deployments focused on distributed monitoring of environmental conditions.
Representative projects include the Great Duck
Island~\cite{spm:04habitat,polastre-masters,mainwaring-habitat}, Berkeley
Redwood Forest~\cite{berkeley-redwoods}, and James
Reserve~\cite{cerpa-habitat} deployments. These systems are characterized by
low data rates (sampling intervals on the order of minutes) and very
low-duty-cycle operation to conserve power.  Research in this area has made
valuable contributions in establishing sensor networks as a viable platform
for scientific monitoring and developing essential components used in our
work. 

This previous work has not yet focused on the efficacy of a sensor network as
a scientific instrument.  The best example is the Berkeley Redwood Forest
deployment~\cite{berkeley-redwoods}, which involved 33~nodes monitoring the
microclimate of a redwood tree for 44~days.  Their study focuses on novel
ways of visualizing and presenting the data captured by the sensor network,
as well as on the data yield of the system. The authors show that the
microclimactic measurements are consistent with existing models; however, no
ground truth of the data is established. This paper highlights many of the
challenges involved in using wireless sensors to augment or replace existing
scientific instrumentation.

{\bf High-data-rate monitoring:} A second class of sensor network
applications involves relatively high data rates and precise timing of the
captured signals. The two dominant applications in this area are structural
health monitoring and condition-based maintenance. In each case, arrays of
sensors are used to capture vibration or accelerometer waveforms that must be
appropriately timestamped for later analysis.

NetSHM~\cite{netshm-ewsnsubmission,netshm-emnets05,wisan} is a wireless
sensor network for structural health monitoring, which involves studying the
response of buildings, bridges, and other structures to localize structural
damage, e.g., following an earthquake. This system shares many of the
challenges of geophysical monitoring; indeed, the data rates involved (500~Hz
per channel) are higher than are typically used in volcano studies. 

NetSHM implements reliable data collection using both hop-by-hop caching and
end-to-end retransmissions. Their work explores the use of local computations
on sensors to reduce bandwidth requirements.  Rather than a global
time-synchronization protocol, the base station timestamps each sample upon
reception. The {\em residence time} of each sample as it flows from sensor to
base is calculated based on measurements at each transmission hop and used to
deduce the original sample time.

Several factors distinguish our work. First, NetSHM is designed to collect
signals following controlled excitations of a structure, which simplifies
scheduling.  In our case, volcanic activity is bursty and highly variable,
requiring more sophisticated approaches to event detection and data transfer.
Second, NetSHM has been deployed in relatively dense networks, making data
collection and time synchronization more robust.  Third, to date the NetSHM
evaluations have focused more on network performance and less on the fidelity
of the extracted data.  Other systems for wireless SHM include one developed
by the Stanford Earthquake Engineering
Center~\cite{wimms-lynch06,wimms-wang05} and earlier work by Berkeley on
monitoring the Golden Gate Bridge~\cite{ggb-monitoring}.

Condition-based maintenance is another emerging area for wireless sensor
networks. The typical approach is to collect vibration waveforms from
equipment (e.g., chillers, pumps, etc.) and perform time- and
frequency-domain analysis to determine when the equipment requires servicing.
Intel Research has explored this area through two deployments at a
fabrication plant and an oil tanker in the North
Sea~\cite{intel-northseasensys}. Although this application involves high
sampling rates, it does not necessarily require time synchronization as
signals from multiple sensors need not be correlated.  The initial evaluation
of these deployments only considers the network performance and does not
address data fidelity issues.

% 23 Apr 2006 : GWA : I think that we can cite to GGB in the intro but I
%               can't find a good evaluation.
%
%Another, earlier project using sensor networks for SHM is the Golden Gate
%Bridge project at the University of California, Berkeley~\cite{ggb-report}. This
%work focused largely on developing an architecture for high data-rate sensing
%and reliable data recovery and does not spend any time on data analysis.

% 22 Apr 2006 : GWA : Stuff that didn't get mentioned that I found somewhere:
%
% 1) WiMMS :
% http://eil.stanford.edu/publications/jerry_lynch/SPIE2002Paper.pdf
% http://eil.stanford.edu/publications/jerry_lynch/3WCSCPaper.pdf
% http://eil.stanford.edu/publications/jerry_lynch/USKoreaWSPaper2Sensor.pdf
% http://eil.stanford.edu/publications/yang_wang/IWSHM2005_YangWang_final.pdf
%
% This is Jerry Lynch's group at Stanford and might be worth looking at. They
% do some evaluation. Actually this seems well documented so I think that we
% should look at it.
%
% 2) Group at Notre Dame :
% http://www.nd.edu/~pantsakl/345-ISHMII05.pdf
% http://www.nd.edu/~mhaenggi/pubs/struct06.pdf
%
% This looks like mainly an architecture.

%\subsection{Habitat monitoring}

% 22 Apr 2006 : GWA : I think that maybe this is enough, but maybe mention
%               Zebranet?

% 22 Apr 2006 : GWA : Stuff that didn't get mentioned that I found somewhere:
%
% 1) Group at University of Australia doing "reactive environmental
% monitoring"
% http://www.csse.uwa.edu.au/adhocnets/WSNgroup/soil-water-proj/final.issnip04.25oct.pdf
%
% 2) Estrin's Tier Stuff
% http://lecs.cs.ucla.edu/Publications/papers/tier.pdf

\XXXnote{GWA: Ripped from Sensys'08 background and motivation section.}

\section{Background and Motivation}
\label{lance-sec-motivation}

% Mention general structure: Local storage of signals coupled with 
% a reliable bulk-transfer protocol

Wireless sensor networks are becoming more common for applications
that focus on reliable collection of raw signals at relatively high sampling
rates, as opposed to in-network aggregation of low-data-rate samples.
These applications generally make use of extensive offline analysis 
to study the collected data, and it is often infeasible
or impossible to perform this computation within the network itself.
Even in cases where it is possible to shift computation to the network, a
system designer may wish to extract raw data occasionally for calibration
or testing.  Examples of such applications include structural health
monitoring~\cite{netshm-spots06,ggb-ipsn07,wimms-lynch06}, acoustic
sensing~\cite{vango,vigilnet,girod-ipsn07,enviromic}, distributed camera
networks~\cite{cyclops}, and geophysical monitoring~\cite{volcano-osdi06}.

These systems typically record data to flash at each sensor node 
and make use of a reliable bulk-transfer protocol to collect data at 
a base station. Given that the network is capable of sampling data at
a higher rate than it can be downloaded, it is not possible to 
collect the complete signal from all nodes. 
The system is therefore forced to make
a decision about what data to collect and what to throw away. In most
cases this decision is application-specific: for example, a
volcanologist may be chiefly interested in a specific type of seismic
tremor, and a biologist may be looking for acoustic signatures of a 
specific species of marmot~\cite{girod-ipsn07}. The implication is that
the system must be able to determine the intrinsic {\em value} of
a given signal to determine whether resources should be devoted to 
storing and downloading that signal.

Previous approaches have involved simple mechanisms tailored for 
specific applications. For example, in the
NetSHM~\cite{netshm-spots06,netshm-emnets05} structural monitoring 
system, data collection is 
triggered manually following an excitation of the structure.
Sentri~\cite{ggb-ipsn07} has been used for vibration monitoring at
the Golden Gate Bridge; it is unclear from the paper how sampling and
communication are triggered, but reported experimental results
suggest manual operation. The Reventador volcano monitoring 
system~\cite{volcano-osdi06} used a simple triggering algorithm to detect 
seismic events and initiate reliable transfer to the base station. 
The Intel Predictive Maintenance
system~\cite{intel-northseasensys} performs high-data-rate sampling
staggered over infrequent, periodic collection periods to extend
system lifetime. 
All of these systems involve a tight binding of the {\em mechanisms} 
used to manage storage and bandwidth with their respective 
application-specific {\em policies}.

The typical approach to download management is a FIFO model where downloads
occur in a round-robin fashion across the network once a trigger occurs. In
general, new data may be sampled and stored to flash while a download is
taking place.  Therefore, the trigger frequency, download cycle duration and
the number of nodes in the network all effect the amount of data captured by
such an approach.  For example, the Flush~\cite{flush-sensys07} protocol
achieves only 8~Kbps for a reliable transfer over multiple hops; the
Fetch~\cite{volcano-osdi06} and Straw~\cite{ggb-ipsn07} protocols fare
somewhat worse. The RCRT protocol~\cite{rcrt-sensys07} is designed for a case
where all nodes are transmitting simultaneously to the sink, although this
approach severely limits the obtained per-node throughput. As a result, when
incoming data rates exceed download capacity, FIFO download management can
produce excessive delays between data acquisition and retrieval.

Lance assumes that sensor nodes contain adequate flash storage to buffer
signals prior to download.  While the popular TMote~Sky platform supports a
relatively small 1~MB flash, more recent sensor designs~\cite{shimmer} have
several GB~of flash, and we expect this trend to continue. Rather than
focusing on per-node storage, our primary concern is with limitations on
bandwidth and energy.

Our goal is to develop a general-purpose approach to bandwidth and energy
management that complements a reliable data-collection protocol. Such a
system should have several key properties.  First, it should be {\em
customizable}, allowing different applications to specify their own policies
for storage management and bandwidth prioritization. Second, the system
should target a range of optimization goals. Examples include maximizing
overall data priority, bounding energy consumption, maximizing temporal or
spatial coverage of the collected data, or achieving fairness across sensor
nodes. Third, the system should be decoupled from a specific routing
protocol, reliable collection protocol, or sensor node platform, making it
possible to leverage the system in different settings. 

%As a concrete example, consider a network sampling triaxial accelerometer 
%data at 1~kHz at 16~bits/sample. To download 60~sec of
%this signal at 500~bytes/sec would require 
%(1000 * 3 * 2 * 60)/500 = 720~sec {\em per node}.
%Even assuming transfers from all nodes can be performed in parallel at
%this rate, during this time over 4~MBytes of new data would 
%be sampled, and with a 1~MByte flash we have no choice but to discard 
%most of the data. The fundamental limitation of the FIFO approach is that 
%it makes no attempt to prioritize which data is stored or downloaded. 

